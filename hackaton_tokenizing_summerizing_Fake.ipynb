{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff63b2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuzzysha/software/miniconda3/envs/hproj/lib/python3.8/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.7). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/8k/v_790m6j3ksgsl4j86kmxvsw0000gn/T/ipykernel_85897/526516702.py:30: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.options.display.max_colwidth = -1\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import calendar\n",
    "import string\n",
    "import regex\n",
    "import re\n",
    "import operator\n",
    "from datetime import datetime, date\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import en_core_web_sm\n",
    "from nltk.corpus import stopwords\n",
    "from pysummarization.nlpbase.auto_abstractor import AutoAbstractor\n",
    "from pysummarization.tokenizabledoc.simple_tokenizer import SimpleTokenizer\n",
    "from pysummarization.abstractabledoc.top_n_rank_abstractor import TopNRankAbstractor\n",
    "\n",
    "#Load English language model\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "#Set pandas display options\n",
    "pd.options.display.max_columns = 2000\n",
    "pd.options.display.max_rows = 2000\n",
    "pd.options.display.max_colwidth = -1\n",
    "pd.options.display.max_seq_items = 2000\n",
    "\n",
    "#Set Seaborn theme\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1932a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read databases\n",
    "df_news_true=pd.read_csv('data/DataSet_Misinfo_TRUE.csv',index_col=False)\n",
    "df_news_fake=pd.read_csv('data/DataSet_Misinfo_FAKE.csv')\n",
    "df_news_rpsub=pd.read_csv('data/EXTRA_RussianPropagandaSubset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf43ef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 43642\n",
      "Number of words: 19311894\n"
     ]
    }
   ],
   "source": [
    "# Print the number of rows\n",
    "print(\"Number of rows:\", len(df_news_fake[df_news_fake['text'].isna()==False]['text']))\n",
    "\n",
    "# Combine all sentences in the 'text' column and split by period to create a list of sentences\n",
    "list_of_sent = [('').join(x) for x in df_news_fake[df_news_fake['text'].isna()==False]['text']]\n",
    "all_of_sent = [('. ').join(list_of_sent)]\n",
    "joined_sent = str(all_of_sent[0])\n",
    "\n",
    "# Print the number of words in the combined 'text' column\n",
    "print(\"Number of words:\", len(joined_sent.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d05caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2018 will be a great year for America! As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year.\n",
      " (35.0%)\n",
      "  2018 will be a great year for America! As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year.\n",
      " (34.0%)\n",
      " As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year,  President Angry Pants tweeted.\n",
      " (32.0%)\n",
      " As we say goodbye to an incredibly successful 2017, led by an incredibly successful President, we d like to thank President Trump for the incredible sacrifices he s made on behalf of every American (even those who don t yet understand) to Make America Great Again!President Trump tweeted:  As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year.\n",
      " (22.0%)\n",
      " Instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.\n",
      " (16.0%)\n",
      "Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that.\n",
      " (16.0%)\n",
      "  The former reality show star had just one job to do and he couldn t do it.\n",
      " (15.0%)\n",
      "What kind of president sends a New Year s greeting like this despicable, petty, infantile gibberish? Only Trump! His lack of decency won t even allow him to rise above the gutter long enough to wish the American citizens a happy new year!  Bishop Talbert Swan (@TalbertSwan) December 31, 2017no one likes you  Calvin (@calvinstowell) December 31, 2017Your impeachment would make 2018 a great year for America, but I ll also accept regaining control of Congress.\n",
      " (15.0%)\n",
      " Trump (@realDonaldTrump) December 31, 2017Trump s tweet went down about as welll as you d expect.\n",
      " (14.0%)\n",
      " it s like the former reality show star isn t even trying anymore.\n",
      " (10.0%)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an instance of AutoAbstractor() class.\n",
    "auto_abstractor = AutoAbstractor()\n",
    "\n",
    "# Instantiate an instance of SimpleTokenizer() class and assign it to the `tokenizable_doc` attribute.\n",
    "auto_abstractor.tokenizable_doc = SimpleTokenizer()\n",
    "\n",
    "# Define the delimiter list to split the document into sentences\n",
    "auto_abstractor.delimiter_list = [\".\", \"\\n\"]\n",
    "\n",
    "# Instantiate an instance of TopNRankAbstractor() class and assign it to `abstractable_doc`.\n",
    "abstractable_doc = TopNRankAbstractor()\n",
    "\n",
    "# Summarize the joined sentences using the summarization techniques.\n",
    "# The `summarize()` method takes two arguments: the document to be summarized and the summarization algorithm to be used.\n",
    "# The `auto_abstractor` object is used to tokenize the input text and the `abstractable_doc` object is used to perform the summarization.\n",
    "summary = auto_abstractor.summarize(joined_sent, abstractable_doc)\n",
    "\n",
    "# Extract each sentence along with its score from the summary data\n",
    "score_data=[x[1] for x in summary['scoring_data']]\n",
    "ziped_sen_val=zip(summary['summarize_result'], score_data)\n",
    "sorted_ziped_sen_val=sorted(ziped_sen_val, key = operator.itemgetter(1),reverse=True)\n",
    "\n",
    "# Print each sentence and its score in descending order\n",
    "for i, scoure in sorted_ziped_sen_val:\n",
    "    print(i, \"(\"+str(round(scoure,0))+\"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954fbffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
